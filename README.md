# â™Ÿï¸ Checkers-AI-Web

ğŸ”— **Live Demo:** [real-vs-ai-face-classifier.onrender.com](https://real-vs-ai-face-classifier.onrender.com)  
ğŸ•’ **Note:** This app is hosted on Renderâ€™s free tier.  
It may take 2-3 minutes to wake up on first visit due to cold start for backend.

Play American checkers against a **minimax AI** or another human in real-time, directly in your browser.  
The entire stack (FastAPI + React + WebSockets) is containerised and auto-deployed via GitHub Actions â†’ Render.

---

## âœ¨ Features
| Area              | Details |
| ----------------- | ------- |
| **Game play**     | â€¢ Human vs AI (three depths) &nbsp;â€¢ Human vs Human (room-based WebSocket) &nbsp;â€¢ Undo (AI only) &nbsp;â€¢ Light/Dark theme |
| **AI engine**     | Classic **minimax + Î±-Î² pruning** written from scratch in Python |
| **Tech stack**    | FastAPI Â· Uvicorn Â· React (Vite) Â· WebSockets Â· Docker Â· GitHub Actions CI |
| **Infra-as-Code** | `docker-compose.yml`, backend/frontend `Dockerfile`s, & CI workflow |
| **Prod hosting**  | Two Render services (Docker) â€“ **backend** on port 8000, **frontend** served via Nginx (static) |

---

## ğŸ—ï¸ Project structure

```

.
â”œâ”€â”€ app/                    # FastAPI backend (Python)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ws_manager.py
â”‚   â””â”€â”€ minimax/            # Board + AI logic
â”œâ”€â”€ frontend/               # React client (Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt        # backend deps
â”œâ”€â”€ docker-compose.yml      # local dev stack
â””â”€â”€ ci.yml                  # GitHub Actions â€“ lint, test, build

````

---

## ğŸš€ Quick start

### 1 Â· Clone & run locally

```bash
git clone https://github.com/logvisionn/checkers-ai-web.git
cd checkers-ai-web

# Build + launch both containers
docker-compose up --build
# â†’  frontend on http://localhost:3000
# â†’  backend  on http://localhost:8000  (docs at /docs)
````

### 2 Â· Dev without Docker (optional)

```bash
# backend
pip install -r ../requirements.txt
uvicorn app.main:app --reload

# frontend (separate terminal)
cd ../frontend
npm install
npm run dev            # http://localhost:5173
```

---

## ğŸ› ï¸ Continuous Integration

* **ruff** â€“ Python lint
* **pytest** â€“ backend unit test (`app/tests/`)
* **ESLint** + **Prettier** â€“ React lint/format
* Running on every `push` to `main`; see **Actions** tab for badges.

---

## ğŸ§­ Next steps

In future iterations, I plan to add:

1. **Reinforcement-Learning / Self-Play**  
   Replace the current minimax engine with a modern self-play RL agent (e.g. AlphaZero-style MCTS guided by a neural policy/value network). This will demonstrate end-to-end deep RL skills and produce more human-like, creative gameplay.


2. **Cloud-based HPO Pipeline**  
   Integrate an HPO framework (e.g. Optuna + Ray Tune) to automate tuning of network architectures and hyperparameters, with experiment tracking via Weights & Biases or similar. This showcases scalable, production-ready ML tooling.


---

## Â© License

MIT â€” free for personal and commercial use with attribution.



